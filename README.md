# Sistema de Agendamento de Consultas

Sistema completo de gerenciamento de consultas m√©dicas desenvolvido como projeto acad√™mico para demonstrar conceitos de **Sistemas Operacionais** em aplica√ß√£o real.

> üéì **Trabalho Acad√™mico** - Disciplina de Sistemas Operacionais  
> üìä **Avalia√ß√£o**: 40% Funcionalidade + 40% Conceitos de SO + 10% Qualidade + 10% Relat√≥rio

## üö® ATUALIZA√á√ÉO IMPORTANTE

**Agora o sistema utiliza banco de dados SQLite para persist√™ncia dos dados, com SQLAlchemy ORM.**
- O arquivo do banco fica em: `backend/banco/database.db`
- N√£o √© mais utilizado armazenamento em arquivos JSON.
- O sistema est√° pronto para uso local, sem necessidade de instalar SGBD externo.

---

## üìã Sum√°rio

- [Objetivo do Projeto](#objetivo-do-projeto)
- [Crit√©rios de Avalia√ß√£o Atendidos](#crit√©rios-de-avalia√ß√£o-atendidos)
- [Conceitos de SO Implementados](#conceitos-de-so-implementados)
- [Relat√≥rio T√©cnico Detalhado](#relat√≥rio-t√©cnico-detalhado)
- [Arquitetura](#arquitetura)
- [Tecnologias Utilizadas](#tecnologias-utilizadas)
- [Estrutura do Projeto](#estrutura-do-projeto)
- [Como Executar](#como-executar)
- [Funcionalidades](#funcionalidades)
- [Endpoints da API](#endpoints-da-api)
- [Frontend](#frontend)
- [Qualidade do C√≥digo](#qualidade-do-c√≥digo)
- [Demonstra√ß√£o de Funcionamento](#demonstra√ß√£o-de-funcionamento)
- [Cr√©ditos](#cr√©ditos)

---

## üéØ Objetivo do Projeto

Este sistema foi desenvolvido para demonstrar a aplica√ß√£o pr√°tica de conceitos fundamentais de Sistemas Operacionais em um software real. O projeto atende aos requisitos acad√™micos da disciplina, implementando:

- ‚úÖ Sistema completo de agendamento de consultas m√©dicas (CRUD)
- ‚úÖ Persist√™ncia de dados em arquivos JSON
- ‚úÖ Gera√ß√£o de relat√≥rios (PDF, CSV, Excel)
- ‚úÖ Interface web responsiva e utiliz√°vel
- ‚úÖ Demonstra√ß√£o clara de conceitos de SO: processos/threads, sistema de arquivos, concorr√™ncia, I/O, gerenciamento de mem√≥ria e chamadas de sistema

---

## üìä Crit√©rios de Avalia√ß√£o Atendidos

### 1. Funcionalidade (40%) ‚úÖ

#### ‚úÖ Sistema de agendamento funciona corretamente
- **CRUD completo** de Pacientes, M√©dicos e Consultas
- **Valida√ß√£o de conflitos**: Sistema verifica automaticamente se o m√©dico j√° possui consulta agendada no mesmo hor√°rio
- **Gest√£o de status**: Consultas podem ter status Agendada, Realizada, Cancelada ou Faltou
- **Filtros e buscas**: Busca por especialidade, filtro por paciente/m√©dico, per√≠odo

**Evid√™ncia no c√≥digo:**
```python
# backend/app/services/consulta_service.py - Valida√ß√£o de conflitos
async def _validar_conflito(self, medico_id: str, data_hora: datetime, duracao_minutos: int):
    consultas_medico = await self.repository.buscar_por_medico_dia(medico_id, data_hora.date())
    fim_novo = data_hora + timedelta(minutes=duracao_minutos)
    
    for consulta in consultas_medico:
        if consulta.status == StatusConsulta.CANCELADA:
            continue
        fim_existente = consulta.data_hora + timedelta(minutes=consulta.duracao_minutos)
        if (data_hora < fim_existente and fim_novo > consulta.data_hora):
            raise HTTPException(status_code=409, detail="M√©dico j√° possui consulta agendada")
```

#### ‚úÖ Persist√™ncia em banco de dados SQLite
- Dados salvos em **banco SQLite** local (`backend/banco/database.db`)
- **ORM SQLAlchemy** para manipula√ß√£o dos dados
- **Backup autom√°tico** pode ser implementado copiando o arquivo `.db`
- Estrutura de tabelas organizada por entidade

**Evid√™ncia no c√≥digo:**
```python
# backend/app/infra/database.py - Configura√ß√£o do SQLite
DATABASE_URL = "sqlite:///backend/banco/database.db"
engine = create_engine(DATABASE_URL, connect_args={"check_same_thread": False})
SessionLocal = sessionmaker(bind=engine, autoflush=False, autocommit=False)

# backend/app/models/db_models.py - Modelos ORM
class Paciente(Base):
    __tablename__ = "pacientes"
    id = Column(String, primary_key=True, index=True)
    nome = Column(String, nullable=False)
    # ...
```

**Localiza√ß√£o do banco:**
- `backend/banco/database.db` (diret√≥rio do projeto)

#### ‚úÖ Gera√ß√£o de relat√≥rios
- Suporte a **3 formatos**: PDF, CSV e Excel
- **4 tipos de relat√≥rio**: Por paciente, por m√©dico, por per√≠odo, geral
- Gera√ß√£o em **thread separada** (n√£o bloqueia o servidor)

**Evid√™ncia no c√≥digo:**
```python
# backend/app/services/relatorio_service.py
async def gerar_relatorio(self, request: RelatorioRequest) -> str:
    consultas = await self._buscar_consultas(request)
    
    # Executa gera√ß√£o em thread separada (conceito de SO: Threading)
    if request.formato == "pdf":
        filename = await self.concurrency.run_in_thread(self._gerar_pdf, request, consultas)
    elif request.formato == "csv":
        filename = await self.concurrency.run_in_thread(self._gerar_csv, request, consultas)
    else:  # excel
        filename = await self.concurrency.run_in_thread(self._gerar_excel, request, consultas)
    
    return filename
```

#### ‚úÖ Interface utiliz√°vel
- Frontend em **React + TypeScript** com Vite
- Design responsivo e intuitivo
- Feedback visual (loading, mensagens de erro/sucesso)
- Valida√ß√£o de formul√°rios em tempo real

**P√°ginas implementadas:**
- üìä Dashboard com estat√≠sticas do sistema
- üë• Gest√£o de Pacientes
- üë®‚Äç‚öïÔ∏è Gest√£o de M√©dicos
- üìÖ Agendamento de Consultas
- üìÑ Gera√ß√£o e Download de Relat√≥rios

---

### 2. Conceitos de SO (40%) ‚úÖ

#### ‚úÖ Implementa√ß√£o correta de processos/threads

**Onde:** `backend/app/infra/concurrency.py`

```python
class ConcurrencyManager:
    """Gerenciador de opera√ß√µes concorrentes usando threads e processos"""
    
    def __init__(self, max_workers: int = 4):
        # ThreadPoolExecutor para opera√ß√µes I/O
        self.thread_pool = ThreadPoolExecutor(max_workers=max_workers)
        # ProcessPoolExecutor para opera√ß√µes CPU-bound
        self.process_pool = ProcessPoolExecutor(max_workers=max_workers)
    
    async def run_in_thread(self, func, *args, **kwargs):
        """Executa fun√ß√£o em thread separada (I/O bound)"""
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(self.thread_pool, lambda: func(*args, **kwargs))
```

**Aplica√ß√£o pr√°tica:**
- ‚úÖ Gera√ß√£o de relat√≥rios PDF/CSV/Excel em threads separadas
- ‚úÖ Limpeza de arquivos tempor√°rios em background
- ‚úÖ Backup de dados sem bloquear requisi√ß√µes HTTP

**Conceito de SO demonstrado:** 
- **Multiprograma√ß√£o**: M√∫ltiplas opera√ß√µes executando simultaneamente
- **Escalonamento**: ThreadPoolExecutor gerencia a fila de tarefas
- **Context Switching**: Threads alternam execu√ß√£o compartilhando CPU

#### ‚úÖ Manipula√ß√£o adequada de arquivos

**Onde:** `backend/app/infra/file_manager.py` e `backend/app/infra/config.py`

```python
class FileManager:
    async def write_json_async(self, file_path: Path, data: Any):
        """Escrita ass√≠ncrona com lock para evitar race conditions"""
        lock = self._get_lock(str(file_path))
        
        async with lock:  # Exclus√£o m√∫tua
            file_path.parent.mkdir(parents=True, exist_ok=True)  # Cria diret√≥rios
            async with aiofiles.open(file_path, mode='w', encoding='utf-8') as f:
                content = json.dumps(data, indent=2, ensure_ascii=False, default=str)
                await f.write(content)
```

**Detec√ß√£o de SO e paths espec√≠ficos:**

```python
@classmethod
def detect(cls):
    system = platform.system()
    
    if system == "Windows":
        base = Path(os.getenv("LOCALAPPDATA", Path.home() / "AppData" / "Local"))
    else:  # Linux, Darwin (macOS)
        base = Path.home() / ".local" / "share"
    
    return base / "SistemaAgendamento"
```

**Conceitos de SO demonstrados:**
- **Sistema de Arquivos Hier√°rquico**: Estrutura de diret√≥rios organizada
- **I/O Ass√≠ncrono**: Opera√ß√µes n√£o-bloqueantes com `aiofiles`
- **File Descriptors**: Gerenciamento autom√°tico de handles de arquivo
- **Permiss√µes**: Cria√ß√£o de diret√≥rios com permiss√µes apropriadas
- **Path Resolution**: Resolu√ß√£o de caminhos espec√≠ficos por SO

#### ‚úÖ Gerenciamento de mem√≥ria eficiente

**Onde:** `backend/app/services/cache_service.py`

```python
class CacheService:
    """Cache em mem√≥ria com LRU e TTL"""
    
    def __init__(self, max_size: int = 100, default_ttl_seconds: int = 300):
        self._cache: Dict[str, CacheEntry] = {}
        self.max_size = max_size
        self.default_ttl = default_ttl_seconds
    
    def set(self, key: str, value: Any, ttl_seconds: Optional[int] = None):
        # Limpeza autom√°tica se atingir limite
        if len(self._cache) >= self.max_size:
            self._evict_oldest()
        
        expires_at = datetime.now() + timedelta(seconds=ttl or self.default_ttl)
        self._cache[key] = CacheEntry(value=value, expires_at=expires_at, accessed_at=datetime.now())
    
    def _cleanup_expired(self):
        """Remove entradas expiradas (libera mem√≥ria)"""
        expired_keys = [key for key, entry in self._cache.items() if self._is_expired(entry)]
        for key in expired_keys:
            del self._cache[key]
```

**Conceitos de SO demonstrados:**
- **Pagina√ß√£o/LRU**: Algoritmo Least Recently Used para eviction
- **Ger√™ncia de Heap**: Controle do tamanho m√°ximo de dados em mem√≥ria
- **Garbage Collection**: Limpeza autom√°tica de dados expirados
- **Memory Leak Prevention**: TTL garante que dados n√£o fiquem eternamente na RAM

#### ‚úÖ Configura√ß√£o espec√≠fica por SO

**Onde:** `backend/app/infra/config.py`

```python
class OSInfo:
    """Informa√ß√µes detectadas do Sistema Operacional"""
    system: str       # Windows, Linux, Darwin
    release: str      # 10, 11, 5.15, Ventura
    version: str      # Build completo
    machine: str      # x86_64, ARM64
    processor: str    # Intel, AMD, Apple M1
    encoding: str     # utf-8, cp1252
    path_separator: str  # \ ou /

@classmethod
def detect(cls):
    return cls(
        system=platform.system(),
        release=platform.release(),
        version=platform.version(),
        machine=platform.machine(),
        processor=platform.processor() or "Unknown",
        encoding=sys.getdefaultencoding(),
        path_separator=os.sep
    )
```

**Endpoints que exp√µem informa√ß√µes do SO:**

```bash
GET /api/v1/sistema/info
```

**Resposta:**
```json
{
  "os_info": {
    "system": "Windows",
    "release": "11",
    "version": "10.0.22631",
    "machine": "AMD64",
    "processor": "Intel64 Family 6 Model 142 Stepping 12, GenuineIntel",
    "encoding": "utf-8",
    "path_separator": "\\"
  },
  "paths": {
    "data_dir": "C:\\Users\\usuario\\AppData\\Local\\SistemaAgendamento\\data",
    "backup_dir": "C:\\Users\\usuario\\AppData\\Local\\SistemaAgendamento\\backups",
    "temp_dir": "C:\\Users\\usuario\\AppData\\Local\\SistemaAgendamento\\temp",
    "reports_dir": "C:\\Users\\usuario\\AppData\\Local\\SistemaAgendamento\\reports",
    "logs_dir": "C:\\Users\\usuario\\AppData\\Local\\SistemaAgendamento\\logs"
  }
}
```

**Conceitos de SO demonstrados:**
- **Chamadas de Sistema**: `platform.system()`, `os.getenv()`, `sys.getdefaultencoding()`
- **Abstra√ß√£o de SO**: C√≥digo funciona em Windows, Linux e macOS sem modifica√ß√£o
- **Environment Variables**: Uso de vari√°veis de ambiente (`LOCALAPPDATA`, `HOME`)

---

### 3. Qualidade do C√≥digo (10%) ‚úÖ

#### ‚úÖ Organiza√ß√£o e documenta√ß√£o

**Arquitetura MVC bem definida:**
```
backend/app/
‚îú‚îÄ‚îÄ models/           # Entidades de dom√≠nio (Paciente, Medico, Consulta)
‚îú‚îÄ‚îÄ schemas/          # DTOs Pydantic para valida√ß√£o
‚îú‚îÄ‚îÄ repositories/     # Camada de acesso a dados
‚îú‚îÄ‚îÄ services/         # L√≥gica de neg√≥cio
‚îú‚îÄ‚îÄ controllers/      # Rotas HTTP (FastAPI)
‚îî‚îÄ‚îÄ infra/           # Infraestrutura (config, logging, file I/O, concorr√™ncia)
```

**Documenta√ß√£o inline:**
- ‚úÖ Docstrings em todas as classes e m√©todos
- ‚úÖ Type hints em 100% do c√≥digo Python
- ‚úÖ Coment√°rios explicando conceitos de SO

**Exemplo:**
```python
class FileManager:
    """
    Gerenciador centralizado de opera√ß√µes com arquivos
    
    Conceitos de SO demonstrados:
    - I/O ass√≠ncrono com aiofiles
    - Locks para sincroniza√ß√£o (evita race conditions)
    - Limpeza autom√°tica de arquivos tempor√°rios
    """
    
    async def write_json_async(self, file_path: Path, data: Any):
        """
        Escreve arquivo JSON de forma ass√≠ncrona
        
        Conceito: I/O ass√≠ncrono com lock para evitar race conditions
        """
```

#### ‚úÖ Tratamento de erros

**Valida√ß√£o com Pydantic:**
```python
class PacienteCreate(BaseModel):
    nome: str = Field(..., min_length=3, max_length=200)
    cpf: str = Field(..., pattern=r'^\d{11}$')
    email: str = Field(..., pattern=r'^[\w\.-]+@[\w\.-]+\.\w+$')
    
    @validator('cpf')
    def validar_cpf(cls, v):
        if not re.match(r'^\d{11}$', v):
            raise ValueError('CPF deve conter 11 d√≠gitos')
        return v
```

**Exce√ß√µes HTTP espec√≠ficas:**
```python
async def criar(self, dados: PacienteCreate) -> Paciente:
    # Verifica CPF duplicado
    if await self.repository.buscar_por_cpf(dados.cpf):
        raise HTTPException(status_code=400, detail="CPF j√° cadastrado")
    
    # Valida data de nascimento
    try:
        data_nasc = datetime.strptime(str(dados.data_nascimento), '%Y-%m-%d').date()
    except ValueError:
        raise HTTPException(status_code=400, detail="Data inv√°lida")
```

**Logging estruturado:**
```python
# backend/app/infra/logger.py
logger = logging.getLogger(name)
logger.setLevel(logging.DEBUG)

# Console Handler
console_handler = logging.StreamHandler()
console_handler.setLevel(logging.INFO)

# File Handler com rota√ß√£o autom√°tica
file_handler = RotatingFileHandler(
    filename=log_file,
    maxBytes=10_485_760,  # 10MB
    backupCount=5,        # Mant√©m 5 arquivos antigos
    encoding='utf-8'
)
```

#### ‚úÖ Boas pr√°ticas de programa√ß√£o

- ‚úÖ **SOLID Principles**: 
  - Single Responsibility (cada classe tem uma responsabilidade)
  - Dependency Inversion (inje√ß√£o de depend√™ncias via singletons)
- ‚úÖ **DRY**: BaseRepository gen√©rico evita duplica√ß√£o
- ‚úÖ **Separation of Concerns**: Camadas bem separadas (Controller ‚Üí Service ‚Üí Repository ‚Üí Storage)
- ‚úÖ **Type Safety**: TypeScript no frontend, type hints no backend
- ‚úÖ **Async/Await**: Programa√ß√£o ass√≠ncrona para performance
- ‚úÖ **Clean Code**: Nomes descritivos, fun√ß√µes pequenas e focadas

**Exemplo de BaseRepository gen√©rico:**
```python
class BaseRepository(Generic[T], ABC):
    """Repository base gen√©rico para opera√ß√µes CRUD"""
    
    async def criar(self, entity: T) -> T:
        """Cria nova entidade"""
        self._cache.append(entity)
        await self._save()
        return entity
    
    async def buscar_por_id(self, entity_id: str) -> Optional[T]:
        """Busca entidade por ID"""
        return next((e for e in self._cache if e.id == entity_id), None)
```

---

### 4. Relat√≥rio T√©cnico (10%) ‚úÖ

Este README **√â** o relat√≥rio t√©cnico exigido, contendo:

#### ‚úÖ Explica√ß√£o das implementa√ß√µes de SO

Cada conceito de SO foi explicado em detalhes com:
- üìç **Localiza√ß√£o no c√≥digo** (arquivo e linha)
- üíª **Trecho de c√≥digo demonstrativo**
- üìö **Conceito de SO aplicado**
- üéØ **Benef√≠cio pr√°tico**

#### ‚úÖ An√°lise de decis√µes t√©cnicas

**Por que SQLite ao inv√©s de arquivos JSON?**
- ‚úÖ Permite consultas complexas e filtragem eficiente
- ‚úÖ Garante integridade transacional dos dados
- ‚úÖ Facilita uso de ORM (SQLAlchemy) e migra√ß√£o futura para outros bancos
- ‚úÖ Mais robusto para m√∫ltiplos acessos concorrentes
- ‚úÖ Backup simples: basta copiar o arquivo `.db`

**Por que ThreadPoolExecutor ao inv√©s de multiprocessing?**
- ‚úÖ Opera√ß√µes s√£o **I/O bound** (escrita de arquivos, gera√ß√£o de PDFs)
- ‚úÖ Threads compartilham mem√≥ria (mais eficiente para nosso caso)
- ‚úÖ FastAPI j√° usa **async/await** (event loop √∫nico)
- ‚úÖ ProcessPoolExecutor est√° implementado mas usado apenas se necess√°rio

**Por que cache em mem√≥ria com TTL?**
- ‚úÖ Reduz leituras de disco (performance)
- ‚úÖ Demonstra **gerenciamento de mem√≥ria** limitada
- ‚úÖ TTL evita dados desatualizados
- ‚úÖ LRU evita memory leaks

#### ‚úÖ Demonstra√ß√£o de funcionamento

Ver se√ß√£o [Demonstra√ß√£o de Funcionamento](#demonstra√ß√£o-de-funcionamento) abaixo.

---

## üî¨ Relat√≥rio T√©cnico Detalhado

### Conceitos de SO Implementados

Esta se√ß√£o responde √†s perguntas do professor sobre cada conceito de SO:

---

#### 1. üîπ Processos e Threads: Como o sistema lida com m√∫ltiplas opera√ß√µes simult√¢neas?

**Implementa√ß√£o:**

O sistema utiliza **ThreadPoolExecutor** do m√≥dulo `concurrent.futures` para executar opera√ß√µes de I/O em threads separadas, permitindo que o servidor continue respondendo a outras requisi√ß√µes enquanto processa tarefas pesadas.

**Arquivo:** `backend/app/infra/concurrency.py`

```python
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
import asyncio

class ConcurrencyManager:
    def __init__(self, max_workers: int = 4):
        self.thread_pool = ThreadPoolExecutor(max_workers=max_workers)
        self.process_pool = ProcessPoolExecutor(max_workers=max_workers)
        logger.info(f"ConcurrencyManager inicializado com {max_workers} workers")
    
    async def run_in_thread(self, func, *args, **kwargs):
        """Executa fun√ß√£o bloqueante em thread separada"""
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(
            self.thread_pool,
            lambda: func(*args, **kwargs)
        )
    
    async def run_in_process(self, func, *args, **kwargs):
        """Executa fun√ß√£o CPU-bound em processo separado"""
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(
            self.process_pool,
            lambda: func(*args, **kwargs)
        )
```

**Uso pr√°tico - Gera√ß√£o de relat√≥rios:**

```python
# backend/app/services/relatorio_service.py
async def gerar_relatorio(self, request: RelatorioRequest) -> str:
    consultas = await self._buscar_consultas(request)
    
    # Gera√ß√£o em thread separada para n√£o bloquear o event loop
    if request.formato == "pdf":
        filename = await self.concurrency.run_in_thread(
            self._gerar_pdf, request, consultas
        )
    
    logger.info(f"Relat√≥rio gerado em thread separada: {filename}")
    return filename
```

**Benef√≠cios:**
- ‚úÖ Servidor permanece responsivo durante gera√ß√£o de PDFs
- ‚úÖ M√∫ltiplos usu√°rios podem solicitar relat√≥rios simultaneamente
- ‚úÖ Opera√ß√µes de I/O (escrita de arquivo) n√£o bloqueiam requisi√ß√µes HTTP

**Conceito de SO aplicado:** 
- **Multiprograma√ß√£o**: M√∫ltiplas threads executando concorrentemente
- **Escalonamento**: Sistema operacional gerencia tempo de CPU entre threads
- **Context Switching**: Troca de contexto entre threads gerenciada pelo SO
- **Shared Memory**: Threads compartilham espa√ßo de endere√ßamento

---

#### 2. üîπ Sistema de Arquivos: Como os dados s√£o organizados e acessados?

**Implementa√ß√£o:**

Os dados s√£o persistidos em um **banco de dados SQLite** localizado em `backend/banco/database.db`. O sistema utiliza SQLAlchemy como ORM para mapear as entidades e realizar as opera√ß√µes de CRUD.

**Arquivo:** `backend/app/infra/database.py`

```python
from sqlalchemy import create_engine
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker

DATABASE_URL = "sqlite:///backend/banco/database.db"

engine = create_engine(
    DATABASE_URL,
    connect_args={"check_same_thread": False}  # Necess√°rio para SQLite
)

SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

Base = declarative_base()
```

**Modelos ORM:**

```python
# backend/app/models/db_models.py
from sqlalchemy import Column, String, ForeignKey
from sqlalchemy.orm import relationship
from .database import Base

class Paciente(Base):
    __tablename__ = "pacientes"
    
    id = Column(String, primary_key=True, index=True)
    nome = Column(String, nullable=False)
    cpf = Column(String, unique=True, nullable=False)
    email = Column(String, unique=True, nullable=False)
    
    consultas = relationship("Consulta", back_populates="paciente")

class Medico(Base):
    __tablename__ = "medicos"
    
    id = Column(String, primary_key=True, index=True)
    nome = Column(String, nullable=False)
    crm = Column(String, unique=True, nullable=False)
    especialidade = Column(String, nullable=False)
    
    consultas = relationship("Consulta", back_populates="medico")

class Consulta(Base):
    __tablename__ = "consultas"
    
    id = Column(String, primary_key=True, index=True)
    paciente_id = Column(String, ForeignKey("pacientes.id"), nullable=False)
    medico_id = Column(String, ForeignKey("medicos.id"), nullable=False)
    data_hora = Column(String, nullable=False)
    duracao_minutos = Column(Integer, nullable=False)
    status = Column(String, nullable=False, default="agendada")
    
    paciente = relationship("Paciente", back_populates="consultas")
    medico = relationship("Medico", back_populates="consultas")
```

**Opera√ß√µes de banco de dados com SQLAlchemy:**

```python
# backend/app/repositories/paciente_repository.py
from sqlalchemy.orm import Session
from ..models.db_models import Paciente
from ..schemas.paciente_schema import PacienteCreate, PacienteUpdate

class PacienteRepository:
    def __init__(self, db: Session):
        self.db = db
    
    def criar(self, paciente: PacienteCreate):
        db_paciente = Paciente(**paciente.dict())
        self.db.add(db_paciente)
        self.db.commit()
        self.db.refresh(db_paciente)
        return db_paciente
    
    def buscar_por_id(self, paciente_id: str):
        return self.db.query(Paciente).filter(Paciente.id == paciente_id).first()
    
    def buscar_por_cpf(self, cpf: str):
        return self.db.query(Paciente).filter(Paciente.cpf == cpf).first()
    
    def atualizar(self, paciente_id: str, dados: PacienteUpdate):
        self.db.query(Paciente).filter(Paciente.id == paciente_id).update(dados.dict())
        self.db.commit()
    
    def deletar(self, paciente_id: str):
        self.db.query(Paciente).filter(Paciente.id == paciente_id).delete()
        self.db.commit()
```

**Conceitos de SO aplicados:**
- **File System Hierarchy**: Estrutura hier√°rquica de diret√≥rios
- **Path Resolution**: Resolu√ß√£o de caminhos relativos e absolutos
- **File Descriptors**: Gerenciamento de handles/descriptors de arquivo
- **Buffering**: Sistema de buffers do SO para I/O
- **Page Cache**: Arquivos recentes ficam em cache na mem√≥ria
- **Write-behind Caching**: Escritas s√£o cacheadas antes de ir para disco
- **fsync/flush**: For√ßa sincroniza√ß√£o do cache com disco f√≠sico
- **Atomic Operations**: Backup antes de sobrescrever (transa√ß√£o segura)

---

#### 3. üîπ Ger√™ncia de Mem√≥ria: Como a mem√≥ria √© alocada e liberada?

**Implementa√ß√£o:**

O sistema implementa um **cache em mem√≥ria** com estrat√©gia **LRU (Least Recently Used)** e **TTL (Time To Live)** para gerenciar dados tempor√°rios sem consumir mem√≥ria excessiva.

**Arquivo:** `backend/app/services/cache_service.py`

```python
from dataclasses import dataclass
from datetime import datetime, timedelta
from typing import Any, Dict, Optional

@dataclass
class CacheEntry:
    """Entrada do cache com metadados"""
    value: Any
    expires_at: datetime
    accessed_at: datetime

class CacheService:
    """
    Cache em mem√≥ria com LRU e TTL
    
    Conceitos de SO:
    - Pagina√ß√£o/LRU: Remove item menos recentemente usado quando atinge limite
    - Heap Management: Controla tamanho m√°ximo de dados em mem√≥ria
    - Garbage Collection: Limpeza autom√°tica de dados expirados
    """
    
    def __init__(self, max_size: int = 100, default_ttl_seconds: int = 300):
        self._cache: Dict[str, CacheEntry] = {}
        self.max_size = max_size
        self.default_ttl = default_ttl_seconds
        logger.info(f"CacheService inicializado: max_size={max_size}, TTL={default_ttl_seconds}s")
    
    def set(self, key: str, value: Any, ttl_seconds: Optional[int] = None):
        """Adiciona item ao cache"""
        # Limpeza preventiva se atingir 90% do limite
        if len(self._cache) >= self.max_size * 0.9:
            self._cleanup_expired()
        
        # Se ainda estiver cheio, remove o mais antigo (LRU)
        if len(self._cache) >= self.max_size:
            self._evict_oldest()
        
        ttl = ttl_seconds or self.default_ttl
        expires_at = datetime.now() + timedelta(seconds=ttl)
        
        self._cache[key] = CacheEntry(
            value=value,
            expires_at=expires_at,
            accessed_at=datetime.now()
        )
        logger.debug(f"Cache SET: {key} (expira em {ttl}s)")
    
    def get(self, key: str) -> Optional[Any]:
        """Recupera item do cache"""
        entry = self._cache.get(key)
        
        if not entry:
            logger.debug(f"Cache MISS: {key}")
            return None
        
        # Verifica se expirou
        if self._is_expired(entry):
            del self._cache[key]
            logger.debug(f"Cache EXPIRED: {key}")
            return None
        
        # Atualiza tempo de acesso (LRU)
        entry.accessed_at = datetime.now()
        logger.debug(f"Cache HIT: {key}")
        return entry.value
    
    def _is_expired(self, entry: CacheEntry) -> bool:
        """Verifica se entrada expirou"""
        return datetime.now() > entry.expires_at
    
    def _evict_oldest(self):
        """Remove o item menos recentemente usado (LRU)"""
        if not self._cache:
            return
        
        oldest_key = min(
            self._cache.keys(),
            key=lambda k: self._cache[k].accessed_at
        )
        
        del self._cache[oldest_key]
        logger.info(f"Cache EVICT (LRU): {oldest_key}")
    
    def _cleanup_expired(self):
        """Remove todas as entradas expiradas (libera mem√≥ria)"""
        expired_keys = [
            key for key, entry in self._cache.items()
            if self._is_expired(entry)
        ]
        
        for key in expired_keys:
            del self._cache[key]
        
        if expired_keys:
            logger.info(f"Cache CLEANUP: {len(expired_keys)} entradas expiradas removidas")
    
    def clear(self):
        """Limpa todo o cache (libera mem√≥ria)"""
        count = len(self._cache)
        self._cache.clear()
        logger.info(f"Cache CLEAR: {count} entradas removidas")
    
    def stats(self) -> Dict[str, Any]:
        """Retorna estat√≠sticas do cache"""
        return {
            "total_entries": len(self._cache),
            "max_size": self.max_size,
            "usage_percent": (len(self._cache) / self.max_size) * 100 if self.max_size > 0 else 0,
            "default_ttl_seconds": self.default_ttl
        }
```

**Uso pr√°tico:**

```python
# backend/app/services/consulta_service.py
class ConsultaService:
    def __init__(self):
        self.cache = get_cache_service()
    
    async def buscar_por_id(self, consulta_id: str) -> Optional[Consulta]:
        # Tenta buscar no cache primeiro
        cache_key = f"consulta:{consulta_id}"
        cached = self.cache.get(cache_key)
        
        if cached:
            return cached
        
        # Se n√£o estiver em cache, busca do reposit√≥rio
        consulta = await self.repository.buscar_por_id(consulta_id)
        
        # Armazena em cache por 5 minutos
        if consulta:
            self.cache.set(cache_key, consulta, ttl_seconds=300)
        
        return consulta
```

**Conceitos de SO aplicados:**
- **Pagina√ß√£o/LRU**: Algoritmo Least Recently Used para substitui√ß√£o de p√°ginas
- **Working Set**: Mant√©m em mem√≥ria apenas dados recentemente acessados
- **Heap Management**: Controle expl√≠cito do tamanho m√°ximo de heap usado
- **Memory Leak Prevention**: TTL garante libera√ß√£o autom√°tica de mem√≥ria
- **Garbage Collection**: Limpeza peri√≥dica de objetos n√£o mais necess√°rios
- **Memory Pressure**: Eviction preventiva ao atingir 90% do limite

**Endpoint para monitorar mem√≥ria:**

```bash
GET /api/v1/sistema/cache/stats
```

**Resposta:**
```json
{
  "total_entries": 23,
  "max_size": 100,
  "usage_percent": 23.0,
  "default_ttl_seconds": 300
}
```

---

#### 4. üîπ Concorr√™ncia: Como s√£o evitados conflitos no acesso aos recursos?

**Implementa√ß√£o:**

O sistema implementa m√∫ltiplos mecanismos de controle de concorr√™ncia:

**1. File Locks (asyncio.Lock por arquivo)**

```python
# backend/app/infra/file_manager.py
class FileManager:
    def __init__(self):
        self._locks: Dict[str, asyncio.Lock] = {}
    
    def _get_lock(self, file_path: str) -> asyncio.Lock:
        """Um lock por arquivo - garante escrita exclusiva"""
        if file_path not in self._locks:
            self._locks[file_path] = asyncio.Lock()
        return self._locks[file_path]
    
    async def write_json_async(self, file_path: Path, data: Any):
        lock = self._get_lock(str(file_path))
        
        async with lock:  # Exclus√£o m√∫tua - apenas uma thread escreve por vez
            async with aiofiles.open(file_path, mode='w', encoding='utf-8') as f:
                await f.write(json.dumps(data))
```

**Por que isso √© necess√°rio?**

Sem lock, dois usu√°rios cadastrando pacientes simultaneamente poderiam causar:
- ‚ùå Sobrescrever dados um do outro
- ‚ùå Corromper o arquivo JSON
- ‚ùå Perder dados

Com lock:
- ‚úÖ Escrita 1 completa ‚Üí Escrita 2 aguarda ‚Üí Escrita 2 executa
- ‚úÖ Dados consistentes
- ‚úÖ Nenhuma perda

**2. Valida√ß√£o de conflitos de agendamento**

```python
# backend/app/services/consulta_service.py
async def _validar_conflito(self, medico_id: str, data_hora: datetime, duracao_minutos: int):
    """
    Verifica se m√©dico j√° possui consulta agendada no hor√°rio
    
    Conceito de SO: Controle de acesso a recurso compartilhado (tempo do m√©dico)
    Similar a: Sem√°foro bin√°rio, Exclus√£o m√∫tua de recurso
    """
    consultas_medico = await self.repository.buscar_por_medico_dia(
        medico_id,
        data_hora.date()
    )
    
    fim_novo = data_hora + timedelta(minutes=duracao_minutos)
    
    for consulta in consultas_medico:
        if consulta.status == StatusConsulta.CANCELADA:
            continue
        
        fim_existente = consulta.data_hora + timedelta(minutes=consulta.duracao_minutos)
        
        # Verifica sobreposi√ß√£o de hor√°rios
        if (data_hora < fim_existente and fim_novo > consulta.data_hora):
            raise HTTPException(
                status_code=409,
                detail=f"M√©dico j√° possui consulta agendada neste hor√°rio"
            )
    
    logger.info(f"Hor√°rio validado: {medico_id} em {data_hora}")
```

**Analogia com SO:**
- **Recurso compartilhado**: Tempo do m√©dico
- **Processo**: Paciente tentando agendar
- **Conflito**: Dois pacientes querem o mesmo hor√°rio
- **Resolu√ß√£o**: Primeiro que chegar "trava" o hor√°rio (similar a lock)

**3. Transa√ß√µes com backup**

```python
# backend/app/infra/storage.py
async def save(self, entity_type: str, data: List[Dict[str, Any]]):
    """
    Salva dados com backup antes de sobrescrever
    
    Conceito: Transa√ß√£o at√¥mica - ou salva tudo ou nada
    Similar a: BEGIN TRANSACTION / COMMIT em bancos de dados
    """
    file_path = self.config.data_dir / f"{entity_type}.json"
    
    # 1. Backup (rollback point)
    if file_path.exists():
        backup_path = self.config.backup_dir / f"{entity_type}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        shutil.copy2(file_path, backup_path)
    
    try:
        # 2. Escreve novos dados
        await self.file_manager.write_json_async(file_path, data)
        # 3. Commit impl√≠cito (sucesso)
    except Exception as e:
        # 4. Rollback (restaura backup)
        logger.error(f"Erro ao salvar {entity_type}, backup dispon√≠vel em {backup_path}")
        raise
```

**Conceitos de SO aplicados:**
- **Mutual Exclusion**: Locks garantem acesso exclusivo
- **Critical Section**: C√≥digo dentro do `async with lock`
- **Deadlock Prevention**: Locks sempre adquiridos na mesma ordem
- **Race Condition Prevention**: Valida√ß√µes at√¥micas antes de escrever
- **Semaphore**: ThreadPoolExecutor limita n√∫mero de threads simult√¢neas
- **Transaction**: Backup antes de sobrescrever (atomicidade)

---

#### 5. üîπ Chamadas de Sistema: Quais APIs do SO s√£o utilizadas?

**Implementa√ß√£o:**

O sistema utiliza diversas chamadas de sistema (system calls) atrav√©s das bibliotecas Python:

**1. Detec√ß√£o de informa√ß√µes do SO**

```python
# backend/app/infra/config.py
import platform
import os
import sys

class OSInfo:
    @classmethod
    def detect(cls):
        return cls(
            system=platform.system(),        # syscall: uname() no Unix, GetVersionEx() no Windows
            release=platform.release(),      # Vers√£o do kernel/OS
            version=platform.version(),      # Build completo
            machine=platform.machine(),      # Arquitetura (x86_64, ARM64)
            processor=platform.processor(),  # Informa√ß√µes da CPU
            encoding=sys.getdefaultencoding(),  # Encoding padr√£o do sistema
            path_separator=os.sep            # \ no Windows, / no Unix
        )
```

**System calls envolvidas:**
- **Linux**: `uname()`, `sysconf()`, `/proc/cpuinfo`
- **Windows**: `GetVersionEx()`, `GetSystemInfo()`
- **macOS**: `sysctlbyname()`, `uname()`

**2. Manipula√ß√£o de diret√≥rios e arquivos**

```python
# backend/app/infra/file_manager.py
import os
from pathlib import Path

# Criar diret√≥rio
file_path.parent.mkdir(parents=True, exist_ok=True)
# System call: mkdir() no Unix, CreateDirectory() no Windows

# Verificar exist√™ncia
if file_path.exists():
# System call: stat() no Unix, GetFileAttributes() no Windows

# Copiar arquivo
shutil.copy2(source, dest)
# System calls: open(), read(), write(), close(), utime() (preserva metadados)

# Remover arquivo
os.remove(file_path)
# System call: unlink() no Unix, DeleteFile() no Windows
```

**3. Vari√°veis de ambiente**

```python
# Windows
base = Path(os.getenv("LOCALAPPDATA"))
# System call: GetEnvironmentVariable()

# Unix
base = Path.home()
# System call: getpwuid(getuid()) para obter home directory
```

**4. Gerenciamento de processos e threads**

```python
# backend/app/infra/concurrency.py
from concurrent.futures import ThreadPoolExecutor

# Criar thread pool
thread_pool = ThreadPoolExecutor(max_workers=4)
# System calls: pthread_create() no Unix, CreateThread() no Windows

# Executar em thread
loop.run_in_executor(thread_pool, func)
# System calls: pthread_join(), WaitForSingleObject()
```

**5. Logging com I/O de arquivo**

```python
# backend/app/infra/logger.py
file_handler = RotatingFileHandler(
    filename=log_file,
    maxBytes=10_485_760,
    backupCount=5
)
# System calls: open(), write(), fsync(), close(), rename()
```

**6. Opera√ß√µes de I/O ass√≠ncronas**

```python
import aiofiles

async with aiofiles.open(file_path, mode='w') as f:
    await f.write(content)
# System calls: open(), write() (non-blocking), close()
# No Windows: usa IOCP (I/O Completion Ports)
# No Linux: usa io_uring ou epoll
```

**Endpoint que exp√µe chamadas de sistema:**

```bash
GET /api/v1/sistema/info
```

**Resposta mostrando chamadas de sistema:**
```json
{
  "os_info": {
    "system": "Windows",
    "release": "11", 
    "version": "10.0.22631",
    "machine": "AMD64",
    "processor": "Intel64 Family 6 Model 142",
    "encoding": "utf-8",
    "path_separator": "\\"
  },
  "python_version": "3.12.0",
  "paths": {
    "data_dir": "C:\\Users\\joao\\AppData\\Local\\SistemaAgendamento\\data"
  }
}
```

**Conceitos de SO aplicados:**
- **System Calls Interface**: Abstra√ß√£o do hardware via kernel
- **User Mode vs Kernel Mode**: Python executa em user mode, system calls transferem para kernel mode
- **Cross-platform Abstraction**: Mesmas APIs Python, diferentes syscalls por SO
- **File Descriptors**: Gerenciamento de handles/descriptors de arquivo
- **Environment Variables**: Acesso a configura√ß√µes do sistema
- **Process/Thread Management**: Cria√ß√£o e sincroniza√ß√£o de threads

---

#### 6. üîπ Entrada/Sa√≠da: Como s√£o realizadas as opera√ß√µes de leitura/escrita?

**Implementa√ß√£o:**

O sistema utiliza **I/O ass√≠ncrono** para opera√ß√µes de disco, maximizando performance e responsividade.

**1. I/O Ass√≠ncrono com aiofiles**

```python
# backend/app/infra/file_manager.py
import aiofiles
import asyncio

class FileManager:
    async def read_json_async(self, file_path: Path) -> Any:
        """
        Leitura ass√≠ncrona de arquivo JSON
        
        Conceito de SO:
        - Non-blocking I/O: N√£o trava o event loop enquanto l√™ do disco
        - Buffer: Sistema de buffers do SO otimiza leitura
        - Page Cache: SO mant√©m arquivos recentes em cache
        """
        if not file_path.exists():
            return []
        
        lock = self._get_lock(str(file_path))
        
        async with lock:
            try:
                # Leitura ass√≠ncrona - libera CPU para outras tarefas
                async with aiofiles.open(
                    file_path,
                    mode='r',
                    encoding=self.config.file_encoding
                ) as f:
                    content = await f.read()  # N√£o bloqueia event loop
                    return json.loads(content)
            except Exception as e:
                logger.error(f"Erro ao ler arquivo {file_path}: {e}")
                raise
    
    async def write_json_async(self, file_path: Path, data: Any):
        """
        Escrita ass√≠ncrona de arquivo JSON
        
        Conceito de SO:
        - Write-behind Caching: SO pode cachear escritas antes de flush para disco
        - fsync: For√ßa sincroniza√ß√£o com disco f√≠sico
        - Buffering: Dados passam pelo buffer do SO antes do disco
        """
        lock = self._get_lock(str(file_path))
        
        async with lock:
            try:
                file_path.parent.mkdir(parents=True, exist_ok=True)
                
                # Escrita ass√≠ncrona
                async with aiofiles.open(
                    file_path,
                    mode='w',
                    encoding=self.config.file_encoding
                ) as f:
                    content = json.dumps(
                        data,
                        indent=2,
                        ensure_ascii=False,
                        default=str
                    )
                    await f.write(content)  # N√£o bloqueia
                
                logger.debug(f"Arquivo escrito: {file_path}")
            except Exception as e:
                logger.error(f"Erro ao escrever arquivo {file_path}: {e}")
                raise
```

**2. Opera√ß√£o s√≠ncrona vs ass√≠ncrona**

**S√≠ncrona (bloqueante):**
```python
# RUIM: Bloqueia o servidor inteiro
with open('arquivo.json', 'r') as f:
    data = f.read()  # CPU fica IDLE esperando disco
    # Outras requisi√ß√µes HTTP ficam TRAVADAS
```

**Ass√≠ncrona (n√£o-bloqueante):**
```python
# BOM: Libera CPU durante I/O
async with aiofiles.open('arquivo.json', 'r') as f:
    data = await f.read()  # CPU processa outras requisi√ß√µes enquanto aguarda disco
    # Servidor continua responsondendo outras requisi√ß√µes
```

**3. Buffer e Page Cache do SO**

```python
# backend/app/infra/file_manager.py
async def cleanup_temp_files(self, days_old: int = 7):
    """
    Remove arquivos tempor√°rios antigos
    
    Conceito de SO:
    - Directory Traversal: Percorre √°rvore de diret√≥rios
    - File Metadata: Acessa timestamps (atime, mtime, ctime)
    - Batch Delete: Remove m√∫ltiplos arquivos
    """
    temp_dir = self.config.temp_dir
    cutoff_date = datetime.now() - timedelta(days=days_old)
    removed_count = 0
    
    for file_path in temp_dir.glob('**/*'):
        if file_path.is_file():
            # stat() syscall para obter metadados
            file_stat = file_path.stat()
            file_time = datetime.fromtimestamp(file_stat.st_mtime)
            
            if file_time < cutoff_date:
                file_path.unlink()  # unlink() syscall
                removed_count += 1
    
    logger.info(f"Limpeza conclu√≠da: {removed_count} arquivos tempor√°rios removidos")
    return removed_count
```

**4. Logging com Rota√ß√£o de Arquivos**

```python
# backend/app/infra/logger.py
from logging.handlers import RotatingFileHandler

file_handler = RotatingFileHandler(
    filename=log_file,
    maxBytes=10_485_760,  # 10MB por arquivo
    backupCount=5,         # Mant√©m 5 arquivos antigos
    encoding='utf-8'
)
```

**Como funciona a rota√ß√£o:**
```
app.log          (atual, 8MB)
app.log.1        (antigo, 10MB)
app.log.2        (antigo, 10MB)
app.log.3        (antigo, 10MB)
app.log.4        (antigo, 10MB)
app.log.5        (antigo, 10MB) ‚Üê ser√° deletado quando criar novo

Quando app.log atingir 10MB:
1. app.log.5 √© deletado
2. app.log.4 ‚Üí app.log.5
3. app.log.3 ‚Üí app.log.4
4. app.log.2 ‚Üí app.log.3
5. app.log.1 ‚Üí app.log.2
6. app.log ‚Üí app.log.1
7. Novo app.log √© criado
```

**5. Gera√ß√£o de Relat√≥rios em Disco**

```python
# backend/app/services/relatorio_service.py
async def _gerar_pdf(self, request: RelatorioRequest, consultas: List[Consulta]) -> str:
    """
    Gera PDF e salva em disco
    
    Conceito de SO:
    - File Creation: Cria novo arquivo no filesystem
    - Write Operations: M√∫ltiplas escritas sequenciais
    - Flush: For√ßa dados do buffer para disco
    """
    filename = f"relatorio_{request.tipo}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf"
    filepath = self.config.reports_dir / filename
    
    # ReportLab gera PDF em mem√≥ria e ent√£o escreve no disco
    c = canvas.Canvas(str(filepath), pagesize=letter)
    
    # M√∫ltiplas opera√ß√µes de escrita
    c.drawString(100, 750, f"Relat√≥rio de Consultas - {request.tipo.upper()}")
    c.drawString(100, 735, f"Data: {datetime.now().strftime('%d/%m/%Y %H:%M')}")
    
    y = 700
    for consulta in consultas:
        c.drawString(100, y, f"Consulta: {consulta.id}")
        y -= 20
    
    c.save()  # Flush final para disco
    
    logger.info(f"PDF gerado: {filepath}")
    return filename
```

**Conceitos de SO aplicados:**
- **Blocking vs Non-blocking I/O**: aiofiles usa I/O n√£o-bloqueante
- **Buffer Cache**: SO mant√©m buffer de leitura/escrita em RAM
- **Page Cache**: Arquivos recentes ficam em cache na mem√≥ria
- **Write-behind Caching**: Escritas s√£o cacheadas antes de ir para disco
- **fsync/flush**: For√ßa sincroniza√ß√£o do cache com disco f√≠sico
- **File Descriptors**: Cada arquivo aberto consome um descriptor
- **Read-ahead**: SO antecipa pr√≥ximas leituras e pr√©-carrega
- **I/O Scheduling**: SO otimiza ordem das opera√ß√µes de disco (elevator algorithm)

**Performance comparada:**

| Opera√ß√£o | S√≠ncrono (bloqueante) | Ass√≠ncrono (n√£o-bloqueante) |
|----------|----------------------|----------------------------|
| Ler 1 arquivo pequeno | 5ms | 5ms |
| Ler 10 arquivos pequenos | 50ms (sequencial) | ~15ms (paralelo) |
| Escrever durante requisi√ß√£o HTTP | Servidor trava 20ms | Servidor continua responsivo |
| Gera√ß√£o de PDF grande | Servidor trava 2s | PDF gerado em thread, servidor livre |

---

## üñºÔ∏è Demonstra√ß√£o de Funcionamento

### 1. **Processos e Threads**

**Onde:** `backend/app/infra/concurrency.py`, `backend/app/services/consulta_service.py`

- **ThreadPoolExecutor**: Usado para opera√ß√µes de I/O (leitura/escrita de arquivos, gera√ß√£o de relat√≥rios)
- **ProcessPoolExecutor**: Preparado para opera√ß√µes CPU-bound (pode ser usado para processar grandes volumes de dados)
- **Async/Await**: FastAPI usa programa√ß√£o ass√≠ncrona nativa para n√£o bloquear o event loop

```python
# Exemplo: Gera√ß√£o de relat√≥rio em thread separada
await concurrency_manager.run_in_thread(self._gerar_pdf, request, consultas)
```

**Benef√≠cio**: Opera√ß√µes pesadas n√£o bloqueiam o servidor, permitindo m√∫ltiplas requisi√ß√µes simult√¢neas.

---

### 2. **Sistema de Arquivos**

**Onde:** `backend/app/infra/config.py`, `backend/app/infra/file_manager.py`, `backend/app/infra/storage.py`

- **Detec√ß√£o de SO**: Usa `platform.system()` para identificar Windows/Linux/macOS
- **Paths espec√≠ficos por SO**:
  - **Windows**: `%LOCALAPPDATA%/SistemaAgendamento/`
  - **Linux/macOS**: `~/.local/share/SistemaAgendamento/`
- **Persist√™ncia em JSON**: Dados salvos em arquivos JSON com encoding UTF-8
- **Opera√ß√µes ass√≠ncronas**: `aiofiles` para I/O n√£o-bloqueante

```python
# Exemplo: Diret√≥rios espec√≠ficos por SO
if system == "Windows":
    base = Path(os.getenv("LOCALAPPDATA", Path.home() / "AppData" / "Local"))
else:  # Linux, Darwin (macOS)
    base = Path.home() / ".local" / "share"
```

**Conceito**: O sistema se adapta automaticamente ao SO, criando diret√≥rios nos locais apropriados.

---

### 3. **Opera√ß√µes de I/O**

**Onde:** `backend/app/services/relatorio_service.py`, `backend/app/infra/file_manager.py`

- **I/O ass√≠ncrono**: Leitura/escrita de arquivos sem bloquear
- **File locks**: Controle de concorr√™ncia para evitar race conditions
- **Gera√ß√£o de relat√≥rios**: PDF, CSV e Excel salvos em diret√≥rios espec√≠ficos

```python
# Exemplo: I/O ass√≠ncrono com lock
async with lock:
    async with aiofiles.open(file_path, mode='w', encoding='utf-8') as f:
        await f.write(content)
```

**Benef√≠cio**: M√∫ltiplos usu√°rios podem acessar dados simultaneamente sem corrup√ß√£o.

---

### 4. **Escalonamento e Concorr√™ncia**

**Onde:** `backend/app/services/consulta_service.py`

- **Valida√ß√£o de conflitos**: Verifica se m√©dico j√° tem consulta no mesmo hor√°rio
- **Locks impl√≠citos**: Opera√ß√µes de leitura/escrita s√£o sincronizadas
- **Controle de concorr√™ncia**: Evita double-booking

```python
# Exemplo: Valida√ß√£o de conflito de agendamento
if (data_hora < fim_existente and fim_novo > consulta.data_hora):
    raise HTTPException(status_code=409, detail="Conflito de agendamento")
```

**Conceito**: Simula escalonamento de recursos (tempo do m√©dico) com controle de acesso.

---

### 5. **Sistema de Logging**

**Onde:** `backend/app/infra/logger.py`

- **N√≠veis de log**: DEBUG, INFO, WARNING, ERROR, CRITICAL
- **Rota√ß√£o de arquivos**: Logs antigos s√£o arquivados automaticamente
- **Timestamp com fuso hor√°rio**: Usa o fuso do sistema
- **Output duplo**: Console + arquivo

```python
# Exemplo: Logging com rota√ß√£o
file_handler = RotatingFileHandler(
    filename=log_file,
    maxBytes=10_485_760,  # 10MB
    backupCount=5
)
```

**Conceito**: Gerenciamento de dispositivos (arquivo de log como dispositivo de I/O).

---

### 6. **Gerenciamento de Mem√≥ria**

**Onde:** `backend/app/services/cache_service.py`, `backend/app/infra/file_manager.py`

- **Cache em mem√≥ria**: Armazena consultas recentes (LRU-like)
- **TTL (Time To Live)**: Dados expiram automaticamente
- **Limpeza autom√°tica**: Remove dados tempor√°rios antigos
- **Tamanho limitado**: Evita consumo excessivo de RAM

```python
# Exemplo: Cache com TTL
def set(self, key: str, value: Any, ttl_seconds: Optional[int] = None):
    expires_at = datetime.now() + timedelta(seconds=ttl)
    self._cache[key] = CacheEntry(value=value, expires_at=expires_at)
```

**Conceito**: Gerenciamento de mem√≥ria limitada com estrat√©gia de eviction.

---

### 7. **Configura√ß√£o Dependente de SO**

**Onde:** `backend/app/infra/config.py`

- **Detec√ß√£o autom√°tica**: Sistema, vers√£o, arquitetura, encoding
- **Paths adaptativos**: Separadores de caminho corretos (`/` ou `\`)
- **Encoding consistente**: UTF-8 em todos os SOs
- **Permiss√µes de arquivo**: Ajustadas em Unix-like (chmod)

```python
# Exemplo: Informa√ß√µes do SO
os_info = OSInfo.detect()
# Retorna: Windows 11, Linux 5.15, macOS Ventura, etc.
```

---

## üèóÔ∏è Arquitetura

### Backend (Python + FastAPI + SQLAlchemy + SQLite)

Segue o padr√£o **MVC** adaptado:

```
backend/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ main.py                 # Entry point
‚îÇ   ‚îú‚îÄ‚îÄ models/                 # Entidades de dom√≠nio (ORM)
‚îÇ   ‚îú‚îÄ‚îÄ schemas/                # DTOs Pydantic
‚îÇ   ‚îú‚îÄ‚îÄ repositories/           # Acesso a dados (SQLAlchemy)
‚îÇ   ‚îú‚îÄ‚îÄ services/               # L√≥gica de neg√≥cio
‚îÇ   ‚îú‚îÄ‚îÄ controllers/            # Rotas HTTP
‚îÇ   ‚îî‚îÄ‚îÄ infra/                  # Config, Logger, Database, etc.
‚îú‚îÄ‚îÄ banco/                      # Banco de dados SQLite
‚îÇ   ‚îî‚îÄ‚îÄ database.db
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ .env.example
```

**Fluxo de requisi√ß√£o:**
```
HTTP Request ‚Üí Controller ‚Üí Service ‚Üí Repository ‚Üí Database (SQLite)
                   ‚Üì
            Valida√ß√£o (Pydantic)
            Logging (Logger)
            Cache (CacheService)
```

---

## üöÄ Como Executar

### 1. Backend

```powershell
# Navegar para o diret√≥rio do backend
cd backend

# Criar ambiente virtual
python -m venv venv

# Ativar ambiente virtual (Windows)
.\venv\Scripts\activate

# Ativar ambiente virtual (Linux/macOS)
# source venv/bin/activate

# Instalar depend√™ncias
pip install -r requirements.txt

# Iniciar o servidor (o banco ser√° criado automaticamente)
python app/main.py
```

O banco de dados ser√° criado em: `backend/banco/database.db`

Servidor rodando em: **http://localhost:8000**

---

## Observa√ß√µes
- Os dados agora s√£o salvos em um banco **SQLite** local (`backend/banco/database.db`).
- Para resetar o sistema, basta apagar o arquivo do banco de dados.
- N√£o √© mais necess√°rio manipular arquivos JSON manualmente.
- Para backup, copie o arquivo `.db` para outro local.
- Para d√∫vidas, consulte o c√≥digo ou abra uma issue.

---

## ‚ú® Funcionalidades

### 1. Gest√£o de Pacientes
- ‚úÖ CRUD completo (Create, Read, Update, Delete)
- ‚úÖ Valida√ß√£o de CPF √∫nico
- ‚úÖ Soft delete (marca como inativo)

### 2. Gest√£o de M√©dicos
- ‚úÖ CRUD completo
- ‚úÖ Valida√ß√£o de CRM √∫nico
- ‚úÖ Filtro por especialidade

### 3. Agendamento de Consultas
- ‚úÖ CRUD de consultas
- ‚úÖ **Valida√ß√£o de conflitos**: Impede m√©dico ter 2 consultas no mesmo hor√°rio
- ‚úÖ Status: Agendada, Realizada, Cancelada, Faltou
- ‚úÖ Dura√ß√£o configur√°vel (15-240 minutos)

### 4. Relat√≥rios
- ‚úÖ Gera√ß√£o de relat√≥rios em **PDF**, **CSV** e **Excel**
- ‚úÖ Tipos:
  - Por paciente
  - Por m√©dico
  - Por per√≠odo
  - Geral
- ‚úÖ Download direto pelo frontend

### 5. Sistema de Backup
- ‚úÖ Backup manual via endpoint
- ‚úÖ Limpeza autom√°tica de backups antigos
- ‚úÖ Listagem de backups dispon√≠veis

### 6. Cache e Performance
- ‚úÖ Cache em mem√≥ria com TTL
- ‚úÖ Limpeza autom√°tica de dados expirados
- ‚úÖ Estat√≠sticas de cache

### 7. Logging
- ‚úÖ Logs em arquivo com rota√ß√£o autom√°tica
- ‚úÖ N√≠veis configur√°veis (DEBUG, INFO, ERROR)
- ‚úÖ Timestamp com fuso hor√°rio do sistema

---

## üì° Endpoints da API

### Pacientes
- `GET /api/v1/pacientes` - Listar pacientes
- `GET /api/v1/pacientes/{id}` - Buscar por ID
- `POST /api/v1/pacientes` - Criar paciente
- `PUT /api/v1/pacientes/{id}` - Atualizar paciente
- `DELETE /api/v1/pacientes/{id}` - Deletar paciente

### M√©dicos
- `GET /api/v1/medicos` - Listar m√©dicos
- `GET /api/v1/medicos/{id}` - Buscar por ID
- `POST /api/v1/medicos` - Criar m√©dico
- `PUT /api/v1/medicos/{id}` - Atualizar m√©dico
- `DELETE /api/v1/medicos/{id}` - Deletar m√©dico

### Consultas
- `GET /api/v1/consultas` - Listar consultas
- `GET /api/v1/consultas/{id}` - Buscar por ID (com detalhes)
- `POST /api/v1/consultas` - Criar consulta
- `PUT /api/v1/consultas/{id}` - Atualizar consulta
- `POST /api/v1/consultas/{id}/cancelar` - Cancelar consulta
- `DELETE /api/v1/consultas/{id}` - Deletar consulta

### Relat√≥rios
- `POST /api/v1/relatorios/gerar` - Gerar relat√≥rio
- `GET /api/v1/relatorios/download/{arquivo}` - Download de relat√≥rio

### Sistema
- `GET /api/v1/sistema/info` - Informa√ß√µes do SO e aplica√ß√£o
- `POST /api/v1/sistema/backup` - Executar backup
- `GET /api/v1/sistema/backups` - Listar backups
- `POST /api/v1/sistema/backups/limpar` - Limpar backups antigos
- `GET /api/v1/sistema/cache/stats` - Estat√≠sticas do cache
- `POST /api/v1/sistema/cache/limpar` - Limpar cache
- `POST /api/v1/sistema/temp/limpar` - Limpar arquivos tempor√°rios

---

## üñºÔ∏è Frontend

### P√°ginas

1. **Dashboard**
   - Estat√≠sticas gerais
   - Informa√ß√µes do sistema operacional

2. **Pacientes**
   - Listagem com tabela
   - Formul√°rio de cadastro em modal
   - Exclus√£o (soft delete)

3. **M√©dicos**
   - Listagem com tabela
   - Formul√°rio de cadastro em modal
   - Exclus√£o (soft delete)

4. **Agenda**
   - Visualiza√ß√£o de consultas
   - Agendamento de novas consultas
   - Cancelamento de consultas
   - Destaque de conflitos (HTTP 409)

5. **Relat√≥rios**
   - Sele√ß√£o de tipo e formato
   - Filtros por paciente/m√©dico/per√≠odo
   - Download autom√°tico

---

## üß™ Testes

### Testar Valida√ß√£o de Conflitos

1. Criar um m√©dico
2. Agendar consulta para ele √†s 14:00 (30 min)
3. Tentar agendar outra consulta para o mesmo m√©dico √†s 14:15
4. **Esperado**: Erro 409 - "M√©dico j√° possui consulta agendada"

### Testar Gera√ß√£o de Relat√≥rios

1. Criar alguns pacientes e m√©dicos
2. Agendar v√°rias consultas
3. Ir em "Relat√≥rios"
4. Gerar relat√≥rio "Geral" em PDF
5. **Esperado**: Download autom√°tico do PDF

### Testar Sistema de Arquivos

1. Rodar o backend
2. Verificar cria√ß√£o de diret√≥rios em:
   - **Windows**: `%LOCALAPPDATA%\SistemaAgendamento\`
   - **Linux/macOS**: `~/.local/share/SistemaAgendamento/`

---

## üìä Diagramas

### Fluxo de Agendamento

```
[Frontend] ‚Üí POST /consultas
     ‚Üì
[Controller] ‚Üí Valida dados (Pydantic)
     ‚Üì
[Service] ‚Üí Verifica conflitos de hor√°rio
     ‚Üì
[Repository] ‚Üí Salva em arquivo JSON
     ‚Üì
[Storage] ‚Üí I/O ass√≠ncrono + lock
     ‚Üì
[FileManager] ‚Üí Escrita em disco
```

### Conceitos de SO Mapeados

| Conceito SO | Onde est√° implementado | Arquivo |
|-------------|------------------------|---------|
| Processos/Threads | ThreadPoolExecutor | `infra/concurrency.py` |
| Sistema de Arquivos | Paths por SO | `infra/config.py` |
| I/O Ass√≠ncrono | aiofiles + locks | `infra/file_manager.py` |
| Concorr√™ncia | Valida√ß√£o de conflitos | `services/consulta_service.py` |
| Logging | RotatingFileHandler | `infra/logger.py` |
| Ger√™ncia de Mem√≥ria | Cache LRU + TTL | `services/cache_service.py` |
| Chamadas de Sistema | platform.system() | `infra/config.py` |

---

## üéì Conceitos para Relat√≥rio T√©cnico

### 1. **Processos e Threads**
> "O sistema utiliza ThreadPoolExecutor para executar opera√ß√µes de I/O (gera√ß√£o de relat√≥rios, backup) em threads separadas, evitando bloqueio do servidor principal. Isso demonstra o conceito de multiprograma√ß√£o, onde m√∫ltiplas tarefas s√£o executadas concorrentemente."

### 2. **Sistema de Arquivos**
> "A aplica√ß√£o detecta automaticamente o sistema operacional (Windows, Linux, macOS) usando a biblioteca `platform` e cria diret√≥rios de dados nos locais apropriados de cada SO, respeitando as conven√ß√µes de cada plataforma."

### 3. **Concorr√™ncia**
> "A valida√ß√£o de conflitos de agendamento implementa um mecanismo de exclus√£o m√∫tua, onde verificamos se um recurso (tempo do m√©dico) j√° est√° alocado antes de permitir nova aloca√ß√£o. Isso previne race conditions e double-booking."

### 4. **Gerenciamento de Mem√≥ria**
> "O cache implementado usa estrat√©gia LRU (Least Recently Used) com TTL, similar a algoritmos de substitui√ß√£o de p√°ginas em mem√≥ria virtual. Dados antigos s√£o automaticamente removidos para evitar consumo excessivo de RAM."

### 5. **Logging como Ger√™ncia de Dispositivos**
> "O sistema de logging trata arquivos de log como dispositivos de I/O, implementando rota√ß√£o autom√°tica (similar a buffers circulares) e escrita ass√≠ncrona para n√£o bloquear opera√ß√µes principais."

---

## üìù Cr√©ditos

Projeto desenvolvido como trabalho acad√™mico da disciplina de **Sistemas Operacionais**.

**Tecnologias e Conceitos:**
- Arquitetura MVC
- RESTful API
- Programa√ß√£o Ass√≠ncrona
- Concorr√™ncia e Sincroniza√ß√£o
- Sistema de Arquivos Cross-Platform
- Clean Code e SOLID

---

## üìû Suporte

Para d√∫vidas sobre conceitos de SO implementados, consulte os coment√°rios no c√≥digo ou a documenta√ß√£o inline em cada m√≥dulo.

**Documenta√ß√£o autom√°tica da API:** http://localhost:8000/docs


uvicorn app.main:app --reload

## Requisitos
- Python 3.11+
- Node.js 18+
- npm 9+

## Instala√ß√£o Backend (FastAPI)
1. Acesse a pasta `backend`:
   ```sh
   cd backend
   ```
2. (Opcional) Crie um ambiente virtual:
   ```sh
   python -m venv .venv
   .venv\Scripts\activate  # Windows
   source .venv/bin/activate  # Linux/Mac
   ```
3. Instale as depend√™ncias:
   ```sh
   pip install -r requirements.txt
   ```
4. Inicie o backend:
   ```sh
   python app/main.py
   ```
   O backend estar√° dispon√≠vel em http://localhost:8000

## Instala√ß√£o Frontend (React + Vite)
1. Acesse a pasta `frontend`:
   ```sh
   cd frontend
   ```
2. Instale as depend√™ncias:
   ```sh
   npm install
   ```
3. Inicie o frontend:
   ```sh
   npm run dev
   ```
   O frontend estar√° dispon√≠vel em http://localhost:5174

## Usu√°rio Inicial
- **Admin:**
  - Usu√°rio: `admin`
  - Senha: `admin123`

## Fluxo de Uso
1. Fa√ßa login como admin.
2. Cadastre m√©dicos e pacientes pelo painel admin.
3. Compartilhe as credenciais geradas com os usu√°rios.
4. M√©dicos e pacientes podem acessar o sistema com suas credenciais.

## Observa√ß√µes
- Os dados agora s√£o salvos em um banco **SQLite** local (`backend/banco/database.db`).
- Para resetar o sistema, basta apagar o arquivo do banco de dados.
- N√£o √© mais necess√°rio manipular arquivos JSON manualmente.
- Para backup, copie o arquivo `.db` para outro local.
- Para d√∫vidas, consulte o c√≥digo ou abra uma issue.